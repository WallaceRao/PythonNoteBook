{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3A - Apply & Map, Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Lecture 3A - Apply & Map, Misc](#Lecture-3A---Apply-&-Map,-Misc)\n",
    "\t* &nbsp;\n",
    "\t\t* [Content](#Content)\n",
    "\t\t* [Learning Outcomes](#Learning-Outcomes)\n",
    "\t* [1. Functions and Dataframes - Using *apply()* and *applymap()*](#1.-Functions-and-Dataframes---Using-*apply%28%29*-and-*applymap%28%29*)\n",
    "\t\t* [Functions along an axis](#Functions-along-an-axis)\n",
    "\t\t* [Functions applied element-wise](#Functions-applied-element-wise)\n",
    "\t* [Dummy Variables](#Dummy-Variables)\n",
    "\t* [2. Removing Duplicates](#2.-Removing-Duplicates)\n",
    "\t* [3. Transpose](#3.-Transpose)\n",
    "\t* [4. Shift operations](#4.-Shift-operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Applying functions to dataframes\n",
    "2. Removing duplicates\n",
    "3. Re-shaping dataframes with transpose\n",
    "4. Shift operations for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this lecture, you should be able to:\n",
    "\n",
    "* apply functions to dataframes\n",
    "* remove duplicate rows in dataframes\n",
    "* transpose dataframes\n",
    "* apply shift operations to dataframes for time series data\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "'Pattern matched multiple keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-478bb783e8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set some Pandas options as you like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'html'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yrao/anaconda2/lib/python2.7/site-packages/pandas/core/config.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yrao/anaconda2/lib/python2.7/site-packages/pandas/core/config.pyc\u001b[0m in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_registered_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yrao/anaconda2/lib/python2.7/site-packages/pandas/core/config.pyc\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such keys(s): %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pattern matched multiple keys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOptionError\u001b[0m: 'Pattern matched multiple keys'"
     ]
    }
   ],
   "source": [
    "# Set some Pandas options as you like\n",
    "pd.set_option('html', True)\n",
    "pd.set_option('max_columns', 30)\n",
    "pd.set_option('max_rows', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 10\n",
    "rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functions and Dataframes - Using *apply()* and *applymap()* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in or user-defines functions can be applied along the entire axes of a dataframe.\n",
    "\n",
    "To apply a function to an entire axis (or multiple axes) of a dataframe, we resort to the apply() method, which can take an optional axis argument to determine if the axis is vertical/column-wise (0) or horizontal/row-wise (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.573728</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.088760</td>\n",
       "      <td>0.394099</td>\n",
       "      <td>-1.187847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-1.033031</td>\n",
       "      <td>1.038217</td>\n",
       "      <td>-1.779519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.051218</td>\n",
       "      <td>-0.016920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        one       two     three\n",
       "a -0.573728  0.168971       NaN\n",
       "b  0.088760  0.394099 -1.187847\n",
       "c -1.033031  1.038217 -1.779519\n",
       "d       NaN -0.051218 -0.016920"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),\n",
    "                'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),\n",
    "                'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})\n",
    "\n",
    "df = df[['one','two','three']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of applying a built in sum function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply the mean function to the above dataframe in a row-wise manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply the sum function to columns 'one' and 'two' only in a row-wise manner, and assign the result to a new column in the dataframe called 'four'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Replace the missing value in both columns with the row-wise mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Calculate the column-wise product for the first and third columns only.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Write a function which calculates the sum of a vector and then returns the square of the sum. Once you have done this, apply your function to the dataframe in a row-wise manner, whilst creating a new column 'five', to which you will add insert the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_of_summed_vector(x):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions applied element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply() method produces some form of aggregate calculations on the axes of a dataframe.  applymap() on the other hand extends us the flexibility of applying functions which manipulate single elements in a dataframe.\n",
    "\n",
    "Say we would like to define a function which returns 'pos' for a positive number and alternatively 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg_to_string(x):\n",
    "    if x >= 0:\n",
    "        return 'pos'\n",
    "    else: return 'neg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this to our dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applymap(pos_neg_to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the ability to apply element-wise operations on dataframes is extremely useful when it comes to dataset cleaning and transformations.\n",
    "\n",
    "Let's take a look at a sample from a real-world dataset used for gathering results from a survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig = pd.read_csv(\"../datasets/surveySample.csv\")\n",
    "assig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig.OCCUPATION_M.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the values in this column need to be cleaned up.\n",
    "\n",
    "Let's first find out what all the unique values are in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig.OCCUPATION_M.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write a function that removes the first 3 characters in each entry in order to tidy the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_three_chars(x):\n",
    "    return x.replace(x[:3], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assig[['OCCUPATION_M']].applymap(remove_first_three_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the change permanent, we need to assign the result to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig['OCCUPATION_M'] = assig[['OCCUPATION_M']].applymap(remove_first_three_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dummy Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A dummy variable is a numerical variable used in data analysis to represent subgroups of the sample in under study. \n",
    "\n",
    "In research design, a dummy variable is often used to distinguish different treatment groups. This is accomplished by taking distinct values from a column and creating new columns out of them which are populated with 0 or 1 in order to indicate whether or not the particular data point belongs to this. \n",
    "\n",
    "This is a frequent operation that can be easily in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assig['OCCUPATION_M'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify if there are multiple values within some cells that should be treated as separate columns. In this example we will say that the forward slash indicates a distinct value for which we would like to generate a column for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig['OCCUPATION_M'].str.get_dummies('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** From the assignment dataset, consider the column 'supermarket spend in a week'. The '\\$' character can cause issues in some applications. We want to clean up this column in such a way that the first 3 characters are replaced as well as the '\\$' character, and we also want to change entries with 'No Answer' to reflect that they are actually missing values so replace them with np.NaN. Write a function to do this and apply this function to this column.\n",
    "\n",
    "Verify that your code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assig['supermarket spend in a week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_supermarket_spend(x):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate rows may be naturally occurring in some datasets or they might arise from input errors. In many instances, like machine learning, these duplicate entries need to be removed from the datasets. \n",
    "\n",
    "Dataframes provide straightforward functionality to remove such records.\n",
    "\n",
    "Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'c1': ['one'] * 3 + ['two'] * 4,\n",
    "                  'c2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop_duplicates` returns a DataFrame where the duplicated rows **across all columns** are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a particular column we  would like the duplicates removed from. Let's first make a change to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[1, 'c1'] = 'five'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['c2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `drop_duplicates` by default keep the first observed value combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing is a special form of reshaping tabular data in such a way that the rows become columns and likewise the columns become rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),\n",
    "                'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),\n",
    "                'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})\n",
    "\n",
    "df = df[['one','two','three']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose of a dataframe can be accomplished using either the transpose() method call  or simple .T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose operations are not permanent unless you re-assign the result back tothe original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Slice and select out a dataframe with rows 'c' and 'd' and columns 'one' and 'two', then execute a transpose.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shift operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Shifting” refers to moving data backward and forward through time. Both Series and\n",
    "DataFrame have a  shift method for performing this operation.\n",
    "\n",
    "The dataset below shows the inflation adjusted price of crude oil per barrel from 1948 to 2015 (as of 24/03/2015) and is partially sourced from http://inflationdata.com/Inflation/Inflation_Rate/Historical_Oil_Prices_Table.asp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_price = pd.DataFrame(np.array([[ 1947.  ,    22.81],\n",
    "       [ 1948.  ,    27.21],\n",
    "       [ 1949.  ,    27.48],\n",
    "       [ 1950.  ,    27.19],\n",
    "       [ 1951.  ,    25.2 ],\n",
    "       [ 1952.  ,    24.64],\n",
    "       [ 1953.  ,    25.72],\n",
    "       [ 1954.  ,    26.3 ],\n",
    "       [ 1955.  ,    25.8 ],\n",
    "       [ 1956.  ,    25.56],\n",
    "       [ 1957.  ,    26.38],\n",
    "       [ 1958.  ,    24.55],\n",
    "       [ 1959.  ,    24.3 ],\n",
    "       [ 1960.  ,    23.26],\n",
    "       [ 1961.  ,    22.52],\n",
    "       [ 1962.  ,    22.25],\n",
    "       [ 1963.  ,    22.46],\n",
    "       [ 1964.  ,    22.84],\n",
    "       [ 1965.  ,    22.55],\n",
    "       [ 1966.  ,    22.56],\n",
    "       [ 1967.  ,    22.09],\n",
    "       [ 1968.  ,    21.56],\n",
    "       [ 1969.  ,    21.38],\n",
    "       [ 1970.  ,    20.63],\n",
    "       [ 1971.  ,    21.  ],\n",
    "       [ 1972.  ,    20.33],\n",
    "       [ 1973.  ,    25.06],\n",
    "       [ 1974.  ,    44.71],\n",
    "       [ 1975.  ,    53.55],\n",
    "       [ 1976.  ,    54.37],\n",
    "       [ 1977.  ,    56.08],\n",
    "       [ 1978.  ,    54.16],\n",
    "       [ 1979.  ,    80.9 ],\n",
    "       [ 1980.  ,   107.37],\n",
    "       [ 1981.  ,    92.98],\n",
    "       [ 1982.  ,    77.95],\n",
    "       [ 1983.  ,    68.97],\n",
    "       [ 1984.  ,    65.37],\n",
    "       [ 1985.  ,    59.1 ],\n",
    "       [ 1986.  ,    31.1 ],\n",
    "       [ 1987.  ,    36.89],\n",
    "       [ 1988.  ,    29.73],\n",
    "       [ 1989.  ,    34.91],\n",
    "       [ 1990.  ,    41.79],\n",
    "       [ 1991.  ,    35.03],\n",
    "       [ 1992.  ,    32.4 ],\n",
    "       [ 1993.  ,    27.39],\n",
    "       [ 1994.  ,    24.94],\n",
    "       [ 1995.  ,    25.96],\n",
    "       [ 1996.  ,    30.79],\n",
    "       [ 1997.  ,    27.43],\n",
    "       [ 1998.  ,    17.26],\n",
    "       [ 1999.  ,    23.42],\n",
    "       [ 2000.  ,    37.55],\n",
    "       [ 2001.  ,    30.69],\n",
    "       [ 2002.  ,    29.92],\n",
    "       [ 2003.  ,    35.55],\n",
    "       [ 2004.  ,    47.05],\n",
    "       [ 2005.  ,    60.45],\n",
    "       [ 2006.  ,    68.28],\n",
    "       [ 2007.  ,    72.99],\n",
    "       [ 2008.  ,   100.01],\n",
    "       [ 2009.  ,    58.76],\n",
    "       [ 2010.  ,    77.11],\n",
    "       [ 2011.  ,    91.39],\n",
    "       [ 2012.  ,    88.95],\n",
    "       [ 2013.  ,    92.41],\n",
    "       [ 2014.  ,    89.08],\n",
    "       [ 2015.  ,    47.05]]), columns=['Year','InflationAdjustedPrice'])\n",
    "\n",
    "oil_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to calculate the difference in oil price from one year to the next (something very common in time series analysis), then pandas provides for us a method called shift(), which allows us to select a column and move the data in it up or down by a given amount. \n",
    "\n",
    "In our case, we want to see the difference between the values in price from one year to the next so we will shift the columns by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_price['shifted'] = oil_price.InflationAdjustedPrice.shift(1)\n",
    "oil_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Plot the positive and negative fluctuations of the oil price from year to year for the above dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'],\n",
    "function(utils) {\n",
    "   utils.load_extensions('calico-spell-check', 'calico-document-tools', 'calico-cell-tools');\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
